# Логика написания структуры данных, основанной на хешировании.

Для начала выделим память для одного бакета.
Будем добавлять элементы в структуру, пока 
max_load_factor = кол-во элементов / кол-во бакетов
не превысит некоторое значение, например 2.
Как только это происходит, увеличиваем кол-во бакетов 
в какое-то кол-во раз(опять же можно в 2) и переносим все прошлые 
элементы в новые бакеты.
Так же во время релокации можно сменить и хеш-функцию.

Для разрешения коллизий можно использовать любой удобный способ
адресации: открытый или закрытый.

Однако можно немного модифицировать нашу структуру, 
чтобы обход всех элементов происходил на за время от кол-ва бакетов,
а за время от кол-ва самих элементов, используя идею из
[LRU-кеша](https://github.com/dasfex/ProgrammingNotes/blob/master/general/lru_cache.md).

Будет параллельно хранить двунаправленный лист, в котором будем собственно хранить
сами элементы, а в бакете будем хранить не элемент,
а итератор на ноду листа, в которой начинается цепочка элементов с 
подходящим хешом, а так же можно количество элементов с таким хешом.
Как только приходит новый элемент, мы, вычисляя хеш, получаем ноду,
которая является первой в цепочке элементов с конкретным хешом, 
перед ней вставляем новую ноду, а в бакете кроме увеличения значения 
перезапоминаем прошлую ноду на только что вставленную.
Если мы вставляем элемент с таким хешом впервые, 
то можно новую ноду вставлять например в конец листа(или в начало, как удобно).
Таким образом, в случае, когда нам потребуется обойти все существующие
элементы, мы просто обойдём этот лист за кол-во элементов.

Хотя вообще есть гораздо более интересные методы, 
например вот один из последних докладов: 
[Designing a Fast, Efficient, Cache-friendly Hash Table, Step by Step](
https://www.youtube.com/watch?v=ncHmEUmJZf4
).
